{
  "temperature": 0.2,
  "top_p": 0.95,
  "top_k": null,
  "max_rationale_tokens": [64, 256],
  "stop_tokens": ["</final>"],
  "num_seeds": 10,
  "prompt_template": "Premise: {premise}\nHypothesis: {hypothesis}\nAnswer:"
}
